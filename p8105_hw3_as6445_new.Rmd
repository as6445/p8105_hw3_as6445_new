---
title: "p8105_hw3_as6445"
author: "Ayako Sekiya"
date: "2022-10-07"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(ggridges)
library(patchwork)

library(p8105.datasets)

knitr::opts_chunk$set(
	echo = TRUE,
	warning = FALSE,
	fig.width = 8, 
  fig.height = 6,
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

## Problem 1

#### Read into data

```{r import data}
data("instacart")

instacart=
  instacart
```

There are `r nrow(instacart)` observations and `r ncol(instacart)` columns in the instacart data. The variables included are as following: `r colnames(instacart)`.  

Below is a table summarizing the number of items ordered from aisle. In total, there are 134 aisles, with fresh vegetables and fresh fruits holding the most items ordered by far.

```{r}
instacart %>% 
  count(aisle) %>% 
  arrange(desc(n))
```

```{r}
instacart %>% 
  count(aisle) %>% 
  filter(n > 10000) %>% 
  mutate(aisle = fct_reorder(aisle, n)) %>% 
  ggplot(aes(x = aisle, y = n)) + 
  geom_point() + 
  labs(title = "Number of items ordered in each aisle") +
  theme(axis.text.x = element_text(angle = 60, hjust = 1))

```

```{r}
instacart %>% 
  filter(aisle %in% c("baking ingredients", "dog food care", "packaged vegetables fruits")) %>%
  group_by(aisle) %>% 
  count(product_name) %>% 
  mutate(rank = min_rank(desc(n))) %>% 
  filter(rank < 4) %>% 
  arrange(desc(n)) %>%
  knitr::kable()
```

```{r}
instacart %>%
  filter(product_name %in% c("Pink Lady Apples", "Coffee Ice Cream")) %>%
  group_by(product_name, order_dow) %>%
  summarize(mean_hour = mean(order_hour_of_day)) %>%
  spread(key = order_dow, value = mean_hour) %>%
  knitr::kable(digits = 2)
```

## Problem 2

This problem uses five weeks of accelerometer data collected on a 63 year-old male with BMI 25, who was admitted to the Advanced Cardiac Care Center of Columbia University Medical Center and diagnosed with congestive heart failure (CHF). 

I will first import and tidy the dataset!

```{r tidy accel}
accel = 
  read_csv(file = "./data/accel_data.csv") %>% 
  janitor::clean_names() %>% 
  pivot_longer(
    activity_1:activity_1440, 
    names_to = "activity",
    values_to = "activity_count",
    names_prefix = "activity_") %>% 
  mutate(day_type= ifelse(day=='Saturday','Weekend',
                   ifelse(day=='Sunday','Weekend','Weekday'))) %>% 
    mutate(day=fct_relevel(day, "Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday", "Sunday")) %>% 
    mutate(activity = as.numeric(activity))
      
```

There are `r nrow(accel)` observations and `r ncol(accel)` columns in the Accel data. The variables included in the tidied dataset is as following: `r colnames(accel)`.

#### Using your tidied dataset, aggregate across minutes to create a total activity variable for each day, and create a table showing these totals. Are any trends apparent?

```{r analysis}
accel_analysis = accel %>% 
group_by(day, week) %>% 
  summarize(total_activity = sum(activity_count)) %>% 
  pivot_wider(names_from = day,
              values_from = total_activity)

accel_analysis
```

Based on the table, the person was very sedentary on the 4th and 5th Saturday. However, it is hard to see clear trends based on this table, and a plot might be able to better show trends. The activity levels seem relatively constant on Tuesdays, Wednesdays, and Thursdays. On Sundays, the activity levels decrease throughout the weeks. There is more variation for Monday, Friday and Saturday. 

#### Make a single-panel plot that shows the 24-hour activity time courses for each day and use color to indicate day of the week. Describe in words any patterns or conclusions you can make based on this graph.

I am creating a line plot with a point at the end to better see the trends. 

```{r aggregate}
accel_24 = accel %>% 
  select (day, activity, activity_count, week) %>% 
  ggplot(aes(x =activity , y = activity_count, color=day)) + 
  geom_point()+
   geom_line(alpha = 0.5 ) +  
  labs(
    title = "24-hour activity time for each day by week",
    x = "activity time (min)",
    y = "activity count",
    caption = "Data from accel data") +
  scale_x_continuous(breaks = c(120, 240, 360, 480, 600, 720, 840, 960, 1080, 1200, 1320, 1440)) +
  theme(plot.title = element_text(size = 10, face = "bold"),
        legend.position = "right",
        legend.text = element_text(size = 7),)  
        legend.text = element_text(angle = 90, vjust = 0.5, hjust = 1)
accel_24 

ggsave("accel_24.pdf")
```

From this plot, we can tell that the person is teh most sedentary around sleep hours. This would correspond to the first ~6 hours of the day and the last~2 hours of the day. There seems to be progressively more activity throughout the day which would make sense because the person is awake and most likely moving those hours. There is some variation throughout the weeks depending on this person's schedule. Overall, the person seems to have higher activity on Sundays in the morning hours around 10-12pm and high activity around 8pm on Friday Nights. 

## Problem 3

#### Reading data

```{r read data}
data("ny_noaa")
```

There are `r nrow(ny_noaa)` observations and `r ncol(ny_noaa)` columns in the snow data. The variables included are as following: `r colnames(ny_noaa)`.

There are `r ny_noaa %>% filter(is.na(prcp)) %>% count` missing data in the `prcp` variable. There are `r ny_noaa %>% filter(is.na(snow)) %>% count` missing data in the `snow` variable. There are `r ny_noaa %>% filter(is.na(snwd)) %>% count` missing data in the `snwd` variable. There are `r ny_noaa %>% filter(is.na(tmin)) %>% count` missing data in the `tmin` variable. There are `r ny_noaa %>% filter(is.na(tmax)) %>% count` missing data in the `tmax` variable. 
`
We will first tidy the dataset!

```{r tidy noaa}
ny_noaa<-
  ny_noaa %>% 
  janitor::clean_names() %>%
  separate(date, into=c("year", "month", "day"), sep= "-") %>% 
  mutate(tmax = as.numeric(tmax, na.rm = TRUE)/10,
         tmin = as.numeric(tmin, na.rm = TRUE)/10,
        prcp = as.numeric(prcp, na.rm = TRUE)/10,
        month= as.numeric(month)) %>% 
  mutate(month = month.name[month])
```

`prcp` is converted into mm. `tmax` and `tmin` were also converted into degrees of C. 

#### For snowfall, what are the most commonly observed values? Why?

To answer this question, we will use `group_by` and `summarize`. 

```{r snowfall}
snow=ny_noaa %>% 
  group_by(snow) %>% 
  summarize(n_obs = n())
```

The most commonly observed values is 0 based on the output. This number would make sense because there should be more days that it does not snow in NY than days that snows. This falls in line with our general expectations of the weather in NY. 

#### Make a two-panel plot showing the average max temperature in January and in July in each station across years. 

```{r two panel plot for months}
avg_jan_july_p<-
  ny_noaa %>%
  select( month, id, year, tmax) %>%
  filter(month=='January'|month=='July') %>%
  group_by(id, year, month) %>% 
  summarise(mean_tmax = mean(tmax)) %>%
  drop_na(mean_tmax)%>%
  ggplot(aes(x = year, y = mean_tmax)) +
  geom_point(aes(color=id, alpha = .1))+
  theme(legend.position = "none",
        legend.text = element_text(angle = 90, vjust = 0.5, hjust = 1),
        axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1)) +
  labs(
    title = "Average max temps in January and July",
    x = "Years",
    y = "Average Max daily temperature (C)",
    caption = "Data from the ny noaa package") +
  facet_grid(~month)

avg_jan_july_p

ggsave("avg_jan_july_p.pdf", width=15, height=15)
```

Is there any observable / interpretable structure? Any outliers?

From the two-panel plot, we can see that January has a lower average max temp compared to July, which is understandable. January seems to have a wider spread across all locations throughout the years, in comparison to July. 

There seems to be a few outliers, but the ones to note is an outlier around 1982 in January, and around 1988 in July. It is hard to tell which location, however, due to the abundance of locations and the colors used to represent each dot. Further analysis could be done on these years to figure out which location had an abnormal average max temperatures. 

#### Make a two-panel plot showing (i) tmax vs tmin for the full dataset (note that a scatterplot may not be the best option). 

```{r two-panel tmin and max}
tmax_tmin_p = ny_noaa %>% 
  select(tmax, tmin, year) %>% 
  ggplot(aes(x = tmax, y = tmin)) + 
  geom_hex() + 
  labs(
    title = "Temperature max/ minplot",
    x = "Maximum daily temperature (C)",
    y = "Minimum daily temperature (C)",
    caption = "Data from the ny noaa package")+
  scale_x_continuous(
    breaks = c(-30, -15, 0, 15, 30, 45, 60), 
    labels = c("-30°C","-15°C", "0°C", "15°C", "30°C", "45°C", "60°C")) +
  scale_y_continuous(
    breaks = c(-60, -45, -30, -15, 0, 15, 30, 45, 60), 
    labels = c("-60°C","-45°C","-30°C","-15°C", "0°C", "15°C", "30°C", "45°C", "60°C")) + 
  theme(plot.title = element_text(size = 10, face = "bold"),
                legend.text = element_text(angle = 90, vjust = 0.5, hjust = 1))

tmax_tmin_p

ggsave("tmax_tmin_p.pdf")
```

From this plot, we can see that there are the highest concentrations where there is the lightest color. There seems to be a correlation between minimum and maximum daily temperatures around where there is the most concentrated data. 

#### Make a plot showing the distribution of snowfall values greater than 0 and less than 100 separately by year.

```{r two-panel snowfall}
snow_plot= ny_noaa %>% 
  select (year, snow) %>% 
  filter(snow > 0 & snow < 100) %>% 
  mutate(year = as.character(year)) %>% 
  ggplot(aes(x = year, y = snow, fill = year)) + 
  geom_violin(alpha = 0.5 ) +  
  labs(
    title = "Snowfall distribution (0-100mm) by year",
    x = "Year",
    y = "Snowfall (mm)",
    caption = "Data from the ny noaa package") +
  theme(plot.title = element_text(size = 10, face = "bold"),
        legend.position = "none", 
        axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))

snow_plot

ggsave("snow_plot.pdf")
```

Note: Legends were omitted to better see plots. 

From this plot, there seems to be the highest concentration of snowfall between approximately 0-25mm. The data is skewed to the right, and there are fewer occasions where it snowed more than 75mm of snow throughout the years. 

This is the final two-panel plot. 

```{r combine}
twopanel=tmax_tmin_p+snow_plot

twopanel
```

